{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e24de1b8",
   "metadata": {},
   "source": [
    "# 1. Data Overview\n",
    "\n",
    "This section gives an overview of all the necessary data to train your model and how to download them.\n",
    "\n",
    "## 1.1 Study Area\n",
    "\n",
    "Data set is spread over 98 cities in Europe.The selection of the cities is primarily based on the availability of the population data.\n",
    "\n",
    "\n",
    "## 1.2 Input Data\n",
    "\n",
    "For each city above, we processed the following input data:\n",
    "\n",
    "*Population data:* The European Statistical System (ESSnet) project, in co-operation with the European Forum for Geography and Statistics (EFGS), produced the high resolution (1km) population grids from the population census in Europe. We processed this freely available population grids for each city. \n",
    "\n",
    "*Sentinel-2 (SEN2):* Processed only the RGB bands at 10 m resolution for all four seasonal sets (spring, summer, autumn and winter) of Sentinel-2 images to capture the seasonal variation in the data.\n",
    "\n",
    "*TanDEM-X Digital Elevation Model (DEM):*  Processed the freely available TanDEM-X 90m (3 arcsec) DEM global product that contains the final, global Digital Elevation Model of the landmasses of the Earth.\n",
    "\n",
    "*Local climate zones (LCZ):* Processed the urban local climate zone classifications, So2Sat LCZ v1.0, produced by fusing the freely available satellite data from Sentinel-1 and Sentinel-2 satellites using deep learning.\n",
    "\n",
    "*Nighttime lights (VIIRS):* Processed the freely available cloud free annual composites of global VIIRS nighttime lights.\n",
    "\n",
    "*OpenStreetMap (OSM):* Processed the OSM features such as street density, street length, etc. for each city.\n",
    "\n",
    "*Land use classification (LU):* Mapped OSM tags to a simplified land use classification scheme: commercial, industrial, residential, and other that results in a four band raster with corresponding land use proportions.\n",
    "\n",
    "\n",
    "## 1.3 Data set Preparation\n",
    "\n",
    "Using the processed input data from the step above, we created the patches for each city. The population grid of a city is used as a reference grid to crop all the other input data. The size of a grid cell in the population grid is 1 x1 km and each cell represents the population count living per square km of the cell. \n",
    "\n",
    "For some applications such as environmental impact assessments, land use analysis, climate change, etc. it is sufficient to know the range of the people living in an area. So, we further preprocessed the population grids by binning the population count to a population class. We assigned a grid cell, Class 0, if the population count of the cell is zero, C<sub>cell</sub>=0 if P<sub>cell</sub>=0 and subsequently C<sub>cell</sub>=1 if 2<sup>0</sup> $\\leq$ P<sub>cell</sub> ${<}$ 2<sup>1</sup>, C<sub>cell</sub>=2 if 2<sup>1</sup> $\\leq$ P<sub>cell</sub> ${<}$ 2<sup>2</sup>, C<sub>cell</sub>=3 if 2<sup>2</sup> $\\leq$ P<sub>cell</sub> ${<}$ 2<sup>3</sup>.....C<sub>cell</sub>=${k+1}$ if 2<sup>k</sup> $\\leq$ P<sub>cell</sub> ${<}$ 2<sup>k+1</sup> where k $\\in$ $\\mathbb{N}$. Thus, each grid cell has been assigned a population class depending on which bin its population count falls. It would give more flexibility to the end-users to develop either a regression or a classification model for the task considering the requirements of the application.\n",
    "\n",
    "\n",
    "## 1.4 Data set Structure\n",
    "\n",
    "Data Set consists of two parts, **So2Sat POP Part1** and **So2Sat POP Part2**.\n",
    "\n",
    "*So2Sat POP Part1* consists of the patches from local climate zones, land use classification, nighttime lights, Open Street Map and its features, and from all seasons (autumn, summer, spring, winter) of Sentinel-2 imagery (RGB).\n",
    "\n",
    "*So2Sat POP Part2* consists of patches from digital elevation model only.\n",
    "\n",
    "\n",
    "## 1.5 Demo Data Loader \n",
    "\n",
    "Returns all the patches with attributes of a given data and their corresponding population count and population class labels\n",
    "Note: Reads from both So2Sat POP Part1 and So2Sat POP Part2 data folders.\n",
    "\n",
    "\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "Create a conda environment with python 3.8\n",
    "\n",
    "**Packages:**\n",
    "\n",
    "- matplotlib\n",
    "- opencv-python\n",
    "- pandas\n",
    "- scikit-learn\n",
    "- gdal\n",
    "- rasterio\n",
    "\n",
    "\n",
    "**Note:** Please note that to install GDAL and rasterio, you may need to download the binary wheels for your system (GDAL (https://www.lfd.uci.edu/~gohlke/pythonlibs/#gdal) and rasterio (https://www.lfd.uci.edu/~gohlke/pythonlibs/#rasterio)). Run from the downloads folder.\n",
    "\n",
    "pip install GDAL-3.3.3-cp38-cp38-win_amd64.whl\n",
    "\n",
    "pip install rasterio-1.2.10-cp38-cp38-win_amd64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6755600a",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir_path = \"/local_home/trao_ka/projects/helmholtz_challenges/countMeIn/starter-pack\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f77c264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the paths to the train and test folders\n",
    "\n",
    "import os\n",
    "\n",
    "# paths to the current folder\n",
    "if os.name == \"nt\":  # locally\n",
    "    current_dir_path = os.getcwd()\n",
    "    \n",
    "# paths to So2Sat POP Part1 folder\n",
    "all_patches_mixed_part1 = os.path.join(current_dir_path, 'So2Sat POP Part1')  # path to So2Sat POP Part 1 data folder\n",
    "all_patches_mixed_train_part1 = os.path.join(all_patches_mixed_part1, 'train')   # path to train folder\n",
    "all_patches_mixed_test_part1 = os.path.join(all_patches_mixed_part1, 'test')   # path to test folder\n",
    "\n",
    "# paths to So2Sat POP Part2 folder\n",
    "all_patches_mixed_part2 = os.path.join(current_dir_path, 'So2Sat POP Part2')  # path to So2Sat POP Part 2 data folder\n",
    "all_patches_mixed_train_part2 = os.path.join(all_patches_mixed_part2, 'train')   # path to train folder\n",
    "all_patches_mixed_test_part2 = os.path.join(all_patches_mixed_part2, 'test')   # path to test folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a5d130",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Path to So2Sat POP Part1: ', all_patches_mixed_part1)\n",
    "print('Path to So2Sat POP Part2: ', all_patches_mixed_part2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94159aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_fnames_labels\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"sen2_rgb_autumn\" data in \"train\" folder\n",
    "X_train_sen2_rgb_autumn,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1,\n",
    "                                                                           data='sen2_rgb_autumn')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"sen2_rgb_summer\" data in \"train\" folder\n",
    "X_train_sen2_rgb_summer,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1,\n",
    "                                                                           data='sen2_rgb_summer')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"sen2_rgb_spring\" data in \"train\" folder\n",
    "X_train_sen2_rgb_spring,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1,\n",
    "                                                                           data='sen2_rgb_spring')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"sen2_rgb_winter\" data in \"train\" folder\n",
    "X_train_sen2_rgb_winter,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1,\n",
    "                                                                           data='sen2_rgb_winter')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"viirs\" data in \"train\" folder\n",
    "X_train_viirs,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1, data='viirs')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"lcz\" data in \"train\" folder\n",
    "X_train_lcz,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1, data='lcz')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"lu\" data in \"train\" folder\n",
    "X_train_lu,  y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1, data='lu')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"dem\" data in \"train\" folder\n",
    "X_train_dem, y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part2, data='dem')\n",
    "\n",
    "\n",
    "# load all the files and their corresponding population count and class for \"osm\" data in \"train\" folder\n",
    "X_train_osm, y_train_count, y_train_class = get_fnames_labels(all_patches_mixed_train_part1, data='osm_features')\n",
    "\n",
    "print('All training instances are loaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa847ea",
   "metadata": {},
   "source": [
    "## 1.5 Demo Data Visualization\n",
    "Plot the SEN2, DEM, LCZ, LU, VIIRS paches from train set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418257fb",
   "metadata": {},
   "source": [
    "# 3 Baseline experiment: \n",
    "\n",
    "Selected the popular Random Forest (RF) algorithm, because of its flexibility, efficiency in handling the noisy input data, and relative resistance to overfitting. \n",
    "\n",
    "Implemented the supervised random forest algorithm for regression. The absolute population count is the response variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f533382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b05865d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 2 # Index of the train patch to be plotted\n",
    "\n",
    "fig = plt.figure(figsize=(16, 8))\n",
    "spec = fig.add_gridspec(ncols=4, nrows=3)\n",
    "\n",
    "# Plot SEN2 autumn patch at given index\n",
    "ax = fig.add_subplot(spec[0, 0])\n",
    "if np.max(X_train_sen2_rgb_autumn[index]) - np.min(X_train_sen2_rgb_autumn[index]) == 0:  # to avoid Division by zero\n",
    "    ax.imshow(X_train_sen2_rgb_autumn[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_sen2_rgb_autumn[index] - np.min(X_train_sen2_rgb_autumn[index]))/(np.max(X_train_sen2_rgb_autumn[index]) - np.min(X_train_sen2_rgb_autumn[index])))\n",
    "ax.set_title('SEN2 Autumn train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot SEN2 spring patch at given index\n",
    "ax = fig.add_subplot(spec[0, 1])\n",
    "if np.max(X_train_sen2_rgb_spring[index]) - np.min(X_train_sen2_rgb_spring[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_sen2_rgb_spring[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_sen2_rgb_spring[index] - np.min(X_train_sen2_rgb_spring[index]))/(np.max(X_train_sen2_rgb_spring[index]) - np.min(X_train_sen2_rgb_spring[index])))\n",
    "ax.set_title('SEN2 Spring train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot SEN2 summer patch at given index\n",
    "ax = fig.add_subplot(spec[0, 2])\n",
    "if np.max(X_train_sen2_rgb_summer[index]) - np.min(X_train_sen2_rgb_summer[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_sen2_rgb_summer[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_sen2_rgb_summer[index] - np.min(X_train_sen2_rgb_summer[index]))/(np.max(X_train_sen2_rgb_summer[index]) - np.min(X_train_sen2_rgb_summer[index])))\n",
    "ax.set_title('SEN2 Summer train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot SEN2 winter patch at given index\n",
    "ax = fig.add_subplot(spec[0, 3])\n",
    "if np.max(X_train_sen2_rgb_winter[index]) - np.min(X_train_sen2_rgb_winter[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_sen2_rgb_winter[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_sen2_rgb_winter[index] - np.min(X_train_sen2_rgb_winter[index]))/(np.max(X_train_sen2_rgb_winter[index]) - np.min(X_train_sen2_rgb_winter[index])))\n",
    "ax.set_title('SEN2 Winter train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot DEM patch at given index\n",
    "ax = fig.add_subplot(spec[1, 0])\n",
    "if np.max(X_train_dem[index]) - np.min(X_train_dem[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_dem[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_dem[index] - np.min(X_train_dem[index]))/(np.max(X_train_dem[index]) - np.min(X_train_dem[index])))\n",
    "ax.set_title('DEM train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot LCZ patch at given index\n",
    "ax = fig.add_subplot(spec[1, 1])\n",
    "if np.max(X_train_lcz[index]) - np.min(X_train_lcz[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_lcz[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_lcz[index] - np.min(X_train_lcz[index]))/(np.max(X_train_lcz[index]) - np.min(X_train_lcz[index])))\n",
    "ax.set_title('LCZ train patch')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot LU patch at given index\n",
    "ax = fig.add_subplot(spec[1, 2])\n",
    "if np.max(X_train_lu[index][:,:,0]) - np.min(X_train_lu[index][:,:,0]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_lu[index][:,:,0])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_lu[index][:,:,0] - np.min(X_train_lu[index][:,:,0]))/(np.max(X_train_lu[index][:,:,0]) - np.min(X_train_lu[index][:,:,0])))\n",
    "ax.set_title('LU train patch - Band1')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot LU patch at given index\n",
    "ax = fig.add_subplot(spec[1, 3])\n",
    "if np.max(X_train_lu[index][:,:,1]) - np.min(X_train_lu[index][:,:,1]) == 0: # to avoid Division by zero \n",
    "    ax.imshow(X_train_lu[index][:,:,1])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_lu[index][:,:,1] - np.min(X_train_lu[index][:,:,1]))/(np.max(X_train_lu[index][:,:,1]) - np.min(X_train_lu[index][:,:,1])))\n",
    "ax.set_title('LU train patch - Band2')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot LU patch at given index\n",
    "ax = fig.add_subplot(spec[2, 0])\n",
    "if np.max(X_train_lu[index][:,:,2]) - np.min(X_train_lu[index][:,:,2]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_lu[index][:,:,2])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_lu[index][:,:,2] - np.min(X_train_lu[index][:,:,2]))/(np.max(X_train_lu[index][:,:,2]) - np.min(X_train_lu[index][:,:,2])))\n",
    "ax.set_title('LU train patch - Band3')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot LU patch at given index\n",
    "ax = fig.add_subplot(spec[2, 1])\n",
    "if np.max(X_train_lu[index][:,:,3]) - np.min(X_train_lu[index][:,:,3]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_lu[index][:,:,3])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_lu[index][:,:,3] - np.min(X_train_lu[index][:,:,3]))/(np.max(X_train_lu[index][:,:,3]) - np.min(X_train_lu[index][:,:,3])))\n",
    "ax.set_title('LU train patch - Band4')\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Plot VIIRS patch at given index\n",
    "ax = fig.add_subplot(spec[2, 2])\n",
    "if np.max(X_train_viirs[index]) - np.min(X_train_viirs[index]) == 0: # to avoid Division by zero\n",
    "    ax.imshow(X_train_viirs[index])\n",
    "else:\n",
    "    # normalizing for plotting\n",
    "    ax.imshow((X_train_viirs[index] - np.min(X_train_viirs[index]))/(np.max(X_train_viirs[index]) - np.min(X_train_viirs[index])))\n",
    "ax.set_title('VIIRS train patch')\n",
    "ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7a660",
   "metadata": {},
   "source": [
    "# 2 Data Preprocessing: \n",
    "\n",
    "For each city folder creates a city_name_features.csv file with 125 features in So2Sat POP Part1 folder, this feature set is used for Random Forest training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e298c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create features for training and testing data from So2Sat POP Part1 and So2Sat POP Part2\n",
    "from utils import feature_engineering\n",
    "\n",
    "feature_folder = feature_engineering(all_patches_mixed_part1)\n",
    "feature_folder = feature_engineering(all_patches_mixed_part2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3b85ec",
   "metadata": {},
   "source": [
    "# Load all utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeae002",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import validation_reg, get_perf\n",
    "\n",
    "from rf_regression import rf_regressor\n",
    "from adaboost_regression import adaboost_regressor\n",
    "from gradientboosting_regression import gradientboosting_regressor\n",
    "from voting_regression import voting_regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9aae61a",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2db6827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hp_strategies = ['grid', 'halving']\n",
    "results_based_on_tuning = {}\n",
    "for hp_strategy_i in list_hp_strategies:\n",
    "    ## Random Forest\n",
    "    prediction_csv_RF = rf_regressor(feature_folder, hp_strategy=hp_strategy_i)\n",
    "    print('Predictions save at ', prediction_csv_RF)\n",
    "\n",
    "    # This validation runs only on the sample data set and just for your reference. \n",
    "    validation_csv_path_RF = prediction_csv_RF.replace('prediction', 'validation')\n",
    "    validation_reg(prediction_csv_RF, validation_csv_path_RF, all_patches_mixed_test_part1)\n",
    "\n",
    "\n",
    "    ### Adaboost\n",
    "    prediction_csv_ADA = adaboost_regressor(feature_folder, hp_strategy=hp_strategy_i)\n",
    "    print('Predictions save at ', prediction_csv_ADA)\n",
    "\n",
    "    # This validation runs only on the sample data set and just for your reference. \n",
    "    validation_csv_path_ADA = prediction_csv_ADA.replace('prediction', 'validation')\n",
    "    validation_reg(prediction_csv_ADA, validation_csv_path_ADA, all_patches_mixed_test_part1)\n",
    "\n",
    "\n",
    "    ## Gradient Boosting\n",
    "    prediction_csv_GB = gradientboosting_regressor(feature_folder, hp_strategy=hp_strategy_i)\n",
    "    print('Predictions save at ', prediction_csv_GB)\n",
    "\n",
    "    # This validation runs only on the sample data set and just for your reference. \n",
    "    validation_csv_path_GB = prediction_csv_GB.replace('prediction', 'validation')\n",
    "    validation_reg(prediction_csv_GB, validation_csv_path_GB, all_patches_mixed_test_part1)\n",
    "\n",
    "    ## Voting\n",
    "    prediction_csv_voting = voting_regressor(feature_folder, hp_strategy=hp_strategy_i)\n",
    "    print('Predictions save at ', prediction_csv_voting)\n",
    "\n",
    "    # This validation runs only on the sample data set and just for your reference. \n",
    "    validation_csv_path_voting = prediction_csv_voting.replace('prediction', 'validation')\n",
    "    validation_reg(prediction_csv_voting, validation_csv_path_voting, all_patches_mixed_test_part1)\n",
    "\n",
    "    mae_RF, rmse_RF, rsq_RF = get_perf(prediction_csv_RF, \n",
    "                                       validation_csv_path_RF, \n",
    "                                       all_patches_mixed_test_part1)\n",
    "\n",
    "    mae_ADA, rmse_ADA, rsq_ADA = get_perf(prediction_csv_ADA, \n",
    "                                          validation_csv_path_ADA, \n",
    "                                          all_patches_mixed_test_part1)\n",
    "\n",
    "    mae_GB, rmse_GB, rsq_GB = get_perf(prediction_csv_GB, \n",
    "                                       validation_csv_path_GB, \n",
    "                                       all_patches_mixed_test_part1)\n",
    "\n",
    "    mae_VOTING, rmse_VOTING, rsq_VOTING = get_perf(prediction_csv_voting, \n",
    "                                       validation_csv_path_voting, \n",
    "                                       all_patches_mixed_test_part1)\n",
    "\n",
    "    all_maes = [mae_GB, mae_RF, mae_ADA, mae_VOTING]\n",
    "    all_rmses = [rmse_GB, rmse_RF, rmse_ADA, rmse_VOTING]\n",
    "    all_rsqs = [rsq_GB, rsq_RF, rsq_ADA, rsq_VOTING]\n",
    "    \n",
    "    results_based_on_tuning[hp_strategy_i] = [all_maes, all_rmses, all_rsqs]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4aa4c15",
   "metadata": {},
   "source": [
    "## Ploting of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861521d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_hp_strategies = ['grid', 'halving']\n",
    "list_models = ['gb', 'rf', 'ada', 'voting']\n",
    "\n",
    "# preprocessing\n",
    "dict_maes = dict()\n",
    "dict_rmses = dict()\n",
    "dict_rsqs = dict()\n",
    "\n",
    "for m_i in list_models:\n",
    "    dict_maes[m_i] = list()\n",
    "    dict_rmses[m_i] = list()\n",
    "    dict_rsqs[m_i] = list()\n",
    "\n",
    "for hp_str_i in list_hp_strategies:\n",
    "    \n",
    "    all_maes, all_rmses, all_rsqs = results_based_on_tuning[hp_str_i]\n",
    "    for metric_list, metric_name in [(all_maes, 'MAE'), (all_rmses, 'RMSE'), (all_rsqs, 'R-squared')]:\n",
    "        \n",
    "        \n",
    "        metric_i_gb, metric_i_rf, metric_i_ada, metric_i_voting = metric_list\n",
    "        if metric_name == 'MAE':\n",
    "            dict_maes['gb'].append(metric_i_gb)\n",
    "            dict_maes['rf'].append(metric_i_rf)\n",
    "            dict_maes['ada'].append(metric_i_ada)\n",
    "            dict_maes['voting'].append(metric_i_voting)\n",
    "        elif metric_name == 'RMSE':\n",
    "            dict_rmses['gb'].append(metric_i_gb)\n",
    "            dict_rmses['rf'].append(metric_i_rf)\n",
    "            dict_rmses['ada'].append(metric_i_gb)\n",
    "            dict_rmses['voting'].append(metric_i_voting)\n",
    "        elif metric_name == 'R-squared':\n",
    "            dict_rsqs['gb'].append(metric_i_gb)\n",
    "            dict_rsqs['rf'].append(metric_i_rf)\n",
    "            dict_rsqs['ada'].append(metric_i_ada)\n",
    "            dict_rsqs['voting'].append(metric_i_voting)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973463dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "metric_i_gb, metric_i_rf, metric_i_ada, metric_i_voting = metric_list\n",
    "\n",
    "plt.plot(list_hp_strategies, dict_maes['gb'], \"gd\", label=\"GradientBoostingRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_maes['rf'], \"b^\", label=\"RandomForestRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_maes['ada'], \"ys\", label=\"Adaboost\")\n",
    "plt.plot(list_hp_strategies, dict_maes['voting'], \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "\n",
    "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "plt.ylabel( \"MAE - Validation\")\n",
    "plt.xlabel(\"Tuning\")\n",
    "plt.legend(loc=\"center\")\n",
    "plt.title(\"Regressor predictions - based on tuning strategy used\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e16054e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "metric_i_gb, metric_i_rf, metric_i_ada, metric_i_voting = metric_list\n",
    "\n",
    "plt.plot(list_hp_strategies, dict_rmses['gb'], \"gd\", label=\"GradientBoostingRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_rmses['rf'], \"b^\", label=\"RandomForestRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_rmses['ada'], \"ys\", label=\"Adaboost\")\n",
    "plt.plot(list_hp_strategies, dict_rmses['voting'], \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "\n",
    "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "plt.ylabel( \"RMSE - Validation\")\n",
    "plt.xlabel(\"Tuning\")\n",
    "plt.legend(loc=\"center\")\n",
    "plt.title(\"Regressor predictions - based on tuning strategy used\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b782522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,3))\n",
    "\n",
    "metric_i_gb, metric_i_rf, metric_i_ada, metric_i_voting = metric_list\n",
    "\n",
    "plt.plot(list_hp_strategies, dict_rsqs['gb'], \"gd\", label=\"GradientBoostingRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_rsqs['rf'], \"b^\", label=\"RandomForestRegressor\")\n",
    "plt.plot(list_hp_strategies, dict_rsqs['ada'], \"ys\", label=\"Adaboost\")\n",
    "plt.plot(list_hp_strategies, dict_rsqs['voting'], \"r*\", ms=10, label=\"VotingRegressor\")\n",
    "\n",
    "plt.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "plt.ylabel( \"R-squared - Validation\")\n",
    "plt.xlabel(\"Tuning\")\n",
    "plt.legend(loc=\"center\")\n",
    "plt.title(\"Regressor predictions - based on tuning strategy used\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
